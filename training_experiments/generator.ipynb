{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d18d1679-46bc-463e-9d76-c14018fdf24f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from attrs import define, Factory, asdict\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim import lr_scheduler as torch_lr_scheduler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import (\n",
    "    Union,\n",
    "    Iterable,\n",
    "    Optional,\n",
    "    Sequence,\n",
    "    Tuple,\n",
    "    Any,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fa31f7-fd6c-4076-805c-9d42a7712a92",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05573cf9-19f8-47b4-a0b0-c44be08db521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data paths\n",
    "\n",
    "DATA_PATH = Path(\".\")/\"input\"\n",
    "ALL_TERMS = DATA_PATH/\"all_titles.txt\"\n",
    "TRAIN_TERMS = DATA_PATH/\"train_titles.txt\"\n",
    "VAL_TERMS = DATA_PATH/\"validation_titles.txt\"\n",
    "\n",
    "# Tokenizer\n",
    "\n",
    "PRETRAINED_TOKENIZER = Path(\".\")/\"model\"/\"tokenizer\"/\"pretrained_tokenizer\"\n",
    "\n",
    "# Model\n",
    "\n",
    "MODEL_PATH = Path(\".\")/\"model\"/\"generator\"\n",
    "MODEL_CONFIG = MODEL_PATH/\"config.json\"\n",
    "MODEL_WEIGTHS = MODEL_PATH/\"title_generator.sav\"\n",
    "MODEL_TRAINING_SNAPSHOT = MODEL_PATH/\"snapshot\"/\"generator_training_snapshot.sav\"\n",
    "BEST_METRICS = MODEL_PATH/\"snapshot\"/\"best_metrics.json\"\n",
    "TRAINING_LOG = MODEL_PATH/\"snapshot\"/\"training_log.txt\"\n",
    "\n",
    "# Tensorboard\n",
    "\n",
    "TENSORBOARD_PATH = Path(\".\")/\"img\"/\"tensorboard\"\n",
    "TRAIN = \"Train\"\n",
    "VALIDATION = \"Validation\"\n",
    "LOSS = \"Loss\"\n",
    "\n",
    "# Model parameters\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "MAX_SEQ_LEN = 30  # see query length distribution histogram\n",
    "VOCAB_SIZE = 1528  # see the pre-trained tokenizer parameters\n",
    "HEAD_NUM = 6\n",
    "EMBEDDING_DIM = 128 * HEAD_NUM\n",
    "LAYER_NUM = 6\n",
    "DROPOUT = 0.2\n",
    "\n",
    "EPOCH_NUM = 1000\n",
    "START_EPOCH = 0\n",
    "LOG_INTERVAL = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a349f0d8-d856-4807-9274-8b07d150716b",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d02f0556-90a7-4600-b400-aaeced43863f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@define(kw_only=True)\n",
    "class Config:\n",
    "    attention_head_num: int = HEAD_NUM\n",
    "    embedding_dim: int = EMBEDDING_DIM\n",
    "    decoder_layer_num: int = LAYER_NUM\n",
    "    max_sequence_length: int = MAX_SEQ_LEN\n",
    "    batch_size: int = BATCH_SIZE\n",
    "    dropout: int = DROPOUT\n",
    "    vocab_size: int = VOCAB_SIZE\n",
    "    tokenizer: Union[str, os.PathLike] = PRETRAINED_TOKENIZER\n",
    "    train_data: Union[str, os.PathLike] = TRAIN_TERMS\n",
    "    validation_data: Union[str, os.PathLike] = VAL_TERMS\n",
    "    \n",
    "    @classmethod\n",
    "    def from_json(cls, config_json: Union[str, os.PathLike]):\n",
    "        if not os.path.exists(config_json):\n",
    "            raise FileNotFoundError(f\"Couldn't find {config_json}\")\n",
    "            \n",
    "        with open(config_json, \"r\") as infile:\n",
    "            config = json.load(infile)\n",
    "            config[\"tokenizer\"] = Path(config[\"tokenizer\"])\n",
    "            config[\"train_data\"] = Path(config[\"train_data\"])\n",
    "            config[\"validation_data\"] = Path(config[\"validation_data\"])\n",
    "            return cls(**config)\n",
    "        \n",
    "    def to_json(self, config_json: Union[str, os.PathLike]):\n",
    "        config_dict = asdict(self)\n",
    "        config_dict[\"tokenizer\"] = str(self.tokenizer)\n",
    "        config_dict[\"train_data\"] = str(self.train_data)\n",
    "        config_dict[\"validation_data\"] = str(self.validation_data)\n",
    "        \n",
    "        with open(config_json, \"w\") as outfile:\n",
    "            json.dump(config_dict, outfile, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd691cb4-231c-482f-a1fc-d925ef67fb27",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f1828a-8209-47cd-8f29-052c3a7a7b70",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d078b4f6-7e73-4455-9158-d9736067892d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(data_path: Union[str, os.PathLike],\n",
    "              encoding: Optional[str] = \"utf-8\") -> Iterable[str]:\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(f\"Couldn't find {data_path}\")\n",
    "    with open(data_path, \"r\", encoding=encoding) as infile:\n",
    "        for line in infile:\n",
    "            yield line.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c70a551-b5f5-4383-b168-617bf6da3a89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dump_data_to_txt(data: Sequence[str],\n",
    "                     data_path: Union[str, os.PathLike],\n",
    "                     encoding: Optional[str] = \"utf-8\"):\n",
    "    with open(data_path, \"w\", encoding=encoding) as outfile:\n",
    "        for item in data:\n",
    "            outfile.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96ecff37-1394-4548-906c-c1d3f41136e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_is_split = os.path.exists(TRAIN_TERMS) and os.path.exists(VAL_TERMS)\n",
    "\n",
    "if not dataset_is_split:\n",
    "    data = list(load_data(ALL_TERMS))\n",
    "    train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    dump_data_to_txt(train_data, TRAIN_TERMS)\n",
    "    dump_data_to_txt(val_data, VAL_TERMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc828c0-c61e-4b9c-94ca-b98ef672460d",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61ac92f3-e7f0-47c8-83d9-19918e93a0f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SampleSet:\n",
    "    def __init__(self,\n",
    "                 data: Sequence[str],\n",
    "                 tokenizer: PreTrainedTokenizerFast,\n",
    "                 max_seq_len: int, batch_size: int,\n",
    "                 use_cuda: Optional[bool] = True,\n",
    "                 gpu_num: Optional[int] = 1):\n",
    "        features, targets = self.make_samples(data, tokenizer, max_seq_len)\n",
    "        kwargs = self.make_kwargs(use_cuda, gpu_num)\n",
    "        \n",
    "        self.set = TensorDataset(features, targets)\n",
    "        self.loader = DataLoader(self.set, batch_size=batch_size,\n",
    "                                drop_last=True, shuffle=True, **kwargs)\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_samples(data: Sequence[str], tokenizer: PreTrainedTokenizerFast,\n",
    "                     max_seq_len: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        features, targets = [], []\n",
    "        for item in data:\n",
    "            token_ids = tokenizer.encode(item, add_special_tokens=True, padding=\"max_length\",\n",
    "                                         truncation=True, max_length=max_seq_len + 1,\n",
    "                                         return_tensors=\"pt\").squeeze(dim=0)\n",
    "            features.append(token_ids[:-1])\n",
    "            targets.append(token_ids[1:])\n",
    "            \n",
    "        features = torch.stack(features)\n",
    "        targets = torch.stack(targets)\n",
    "        \n",
    "        return features, targets\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_kwargs(use_cuda: Optional[bool] = True, gpu_num: Optional[int] = 1):\n",
    "        print(f\"Using CUDA: {use_cuda}\")\n",
    "        kwargs = {\n",
    "            \"num_workers\": 4 * gpu_num,\n",
    "            \"pin_memory\": True\n",
    "        } if use_cuda else {}\n",
    "        return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3be9a5e2-3871-48d6-ac32-fb2e0e92f370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@define(kw_only=True)\n",
    "class Dataset:\n",
    "    train: SampleSet\n",
    "    validation: SampleSet\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config: Config):\n",
    "        tokenizer = PreTrainedTokenizerFast.from_pretrained(config.tokenizer)\n",
    "        train_data = list(load_data(config.train_data))\n",
    "        val_data = list(load_data(config.validation_data))\n",
    "        return cls(\n",
    "            train=SampleSet(data=train_data, tokenizer=tokenizer,\n",
    "                            max_seq_len=config.max_sequence_length,\n",
    "                            batch_size=config.batch_size),\n",
    "            validation=SampleSet(data=val_data, tokenizer=tokenizer,\n",
    "                                 max_seq_len=config.max_sequence_length,\n",
    "                                 batch_size=config.batch_size)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1007d06c-87c8-4c0e-933b-67f27b787fa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(MODEL_CONFIG):\n",
    "    config = Config.from_json(MODEL_CONFIG)\n",
    "else:\n",
    "    config = Config()\n",
    "    config.to_json(MODEL_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2cdd16-e25c-4377-abc6-79350c524a80",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5294047d-4438-46cc-8fd5-4d7bb6928993",
   "metadata": {},
   "source": [
    "#### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86f80124-7629-40bf-a41b-05f9cdb34486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, embedding_dim: int, head_dim: int, max_seq_len: int, dropout: float):\n",
    "        super(AttentionHead, self).__init__()\n",
    "        # Query, Key, Value layers\n",
    "        self.query = nn.Linear(embedding_dim, head_dim, bias=False)\n",
    "        self.key = nn.Linear(embedding_dim, head_dim, bias=False)\n",
    "        self.value = nn.Linear(embedding_dim, head_dim, bias=False)\n",
    "        \n",
    "        # A lower triangular matrix to depreciate context from the right\n",
    "        self.register_buffer(\"mask\", torch.tril(torch.ones(max_seq_len, max_seq_len)))\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, _input):\n",
    "        batch_size, seq_len, embedding_dim = _input.shape\n",
    "        k = self.key(_input)\n",
    "        q = self.query(_input)\n",
    "        \n",
    "        # Attention scores --> batch_size x seq_len x seq_len\n",
    "        attention_scores = q @ k.transpose(-2, -1) * embedding_dim ** -0.5\n",
    "        # Set forward context to -inf\n",
    "        attention_scores = attention_scores.masked_fill(\n",
    "            self.mask[:seq_len, :seq_len] == 0,\n",
    "            float(\"-inf\")\n",
    "        )\n",
    "        attention_scores = F.softmax(attention_scores, dim=-1)\n",
    "        attention_scores = self.dropout(attention_scores)\n",
    "        \n",
    "        # Aggregate values by attention\n",
    "        v = self.value(_input)\n",
    "        attention = attention_scores @ v  # batch_size x seq_len x head_dim\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33e8be86-eb03-4641-b688-377e388a24fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim: int, head_dim: int, head_num: int,\n",
    "                 max_seq_len: int, dropout: float):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.attention_heads = nn.ModuleList([\n",
    "            AttentionHead(embedding_dim=embedding_dim, head_dim=head_dim,\n",
    "                          max_seq_len=max_seq_len, dropout=dropout)\n",
    "            for _ in range(head_num)\n",
    "        ])\n",
    "        self.output_layer = nn.Linear(head_dim * head_num, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, _input):\n",
    "        _output = torch.cat(\n",
    "            [\n",
    "                attention_head(_input)\n",
    "                for attention_head\n",
    "                in self.attention_heads\n",
    "            ],\n",
    "            dim=-1\n",
    "        )\n",
    "        _output = self.dropout(self.output_layer(_output))\n",
    "        return _output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fda973-4c69-4bd3-a2b0-86039bb9cb42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "search-suggestions",
   "language": "python",
   "name": "search-suggestions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
